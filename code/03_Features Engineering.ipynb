{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class featureEng:\n",
    "    'Feature Engineering class'\n",
    "    def __init__(self, df, target):\n",
    "        'Initiate feature eng with a csv_file and target'\n",
    "        # read in data frame \n",
    "        \n",
    "        self.df = df\n",
    "        self.target = target\n",
    "        self.features = self.df.drop(target, axis=1)\n",
    "        \n",
    "        self.num_features = self.features.select_dtypes(include='number').columns\n",
    "        self.nom_features = self.features.select_dtypes(exclude='number').columns\n",
    "        \n",
    "        self.dummies = pd.get_dummies(self.df[self.nom_features], drop_first=True) # right now dummying all nominal features\n",
    "        \n",
    "        self.base_df = pd.concat([self.dummies, self.df[self.num_features], self.df[self.target]], axis=1)\n",
    "        \n",
    "        print(f'File shape: {self.df.shape}, Null Values: {self.df.isna().sum().sum()}')\n",
    "        \n",
    "    def feature_dropping(self, drop_features):\n",
    "        # pass in list of feature to drop\n",
    "        \n",
    "        self.base_df = self.base_df.drop([drop_features], axis=1)\n",
    "        print('features dropped!')\n",
    "            \n",
    "    def poly(self, features):\n",
    "        'Transform selected features with Polynomial, add back to base DataFrame. Provided a List of features.'\n",
    "        \n",
    "        # update base dataframe with polys \n",
    "        \n",
    "        \n",
    "        X = self.base_df[features]\n",
    "\n",
    "        poly = PolynomialFeatures(include_bias=False)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "        p_features = poly.get_feature_names(features)\n",
    "        poly_features = pd.DataFrame(X_poly, columns=p_features)\n",
    "\n",
    "        \n",
    "        self.base_df = self.base_df.drop(features, axis=1) # remove features used\n",
    "        \n",
    "        self.base_df = pd.concat([self.base_df, poly_features], axis=1) # add poly features back to base df\n",
    "        \n",
    "        print('DataFrame updated with Polynomial features!')        \n",
    "        \n",
    "    def num_features_score(self, model=LinearRegression):\n",
    "        self.model = model()\n",
    "        \n",
    "        s_val_score = []\n",
    "        s_test_score = []\n",
    "        s_train_score = []\n",
    "        s_features = []\n",
    "        \n",
    "        for feature in self.num_features:\n",
    "            X = self.df[[feature]]\n",
    "            y = self.df[self.target]\n",
    "        \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=32) \n",
    "            self.model.fit(X_train, y_train)\n",
    "            \n",
    "            val_score = cross_val_score(self.model, X_train, y_train, cv=5).mean()\n",
    "            test_score = self.model.score(X_test, y_test)\n",
    "            train_score = self.model.score(X_train, y_train)\n",
    "            \n",
    "            s_features.append(feature)\n",
    "            s_val_score.append(val_score)\n",
    "            s_train_score.append(train_score)\n",
    "            s_test_score.append(test_score)\n",
    "            \n",
    "            summary = {'feature' : s_features, 'val_score' : s_val_score, \n",
    "                       'train_score' : s_train_score, 'test_score' : s_test_score}\n",
    "        \n",
    "        return pd.DataFrame(data=summary).sort_values('val_score', ascending=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_num = ['overall_qual',\n",
    " 'gr_liv_area',\n",
    " 'garage_area',\n",
    " 'garage_cars',\n",
    " 'total_bsmt_sf',\n",
    " '1st_flr_sf',\n",
    " 'year_built',\n",
    " 'year_remod/add',\n",
    " 'garage_yr_blt',\n",
    " 'full_bath']\n",
    "\n",
    "features_nom = ['exterior_2nd', 'mas_vnr_type', 'exter_qual', \n",
    "                'foundation', 'bsmt_exposure', 'bsmtfin_type_1', 'heating_qc', 'kitchen_qual', 'neighborhood',\n",
    "               'bldg_type', 'house_style', 'exterior_1st', 'garage_finish', 'garage_type', 'fireplace_qu']\n",
    "\n",
    "target = ['saleprice']\n",
    "\n",
    "features = features_nom + features_num + target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File shape: (2051, 26), Null Values: 0\n"
     ]
    }
   ],
   "source": [
    "df_features = featureEng(df, 'saleprice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame updated with Polynomial features!\n"
     ]
    }
   ],
   "source": [
    "df_features.poly(df_features.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2051, 175)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.base_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.base_df.to_csv('../datasets/model_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
